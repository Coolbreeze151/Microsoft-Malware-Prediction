{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project \n",
    "This project will focus on Micrsoft Malware Prediction. More details on the problem and dataset can be found in Kaggle [here](https://www.kaggle.com/c/microsoft-malware-prediction)\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "***The malware industry continues to be a well-organized, well-funded market dedicated to evading traditional security measures. Once a computer is infected by malware, criminals can hurt consumers and enterprises in many ways.\n",
    "With more than one billion enterprise and consumer customers, Microsoft takes this problem very seriously and is deeply invested in improving security.\n",
    "As one part of their overall strategy for doing so, Microsoft is challenging the data science community to develop techniques to predict if a machine will soon be hit with malware. As with their previous, Malware Challenge (2015), Microsoft is providing Kagglers with an unprecedented malware dataset to encourage open-source progress on effective techniques for predicting malware occurrences.\n",
    "Can you help protect more than one billion machines from damage BEFORE it happens?***\n",
    "\n",
    "Acknowledgements\n",
    "This competition is hosted by Microsoft, Windows Defender ATP Research, Northeastern University College of Computer and Information Science, and Georgia Tech Institute for Information Security & Privacy.\n",
    "\n",
    "This is a supervised, regression machine learning task: given a set of data with targets (in this case the score) included, we want to train a model that can learn to map the features (also known as the explanatory variables) to the target.\n",
    "\n",
    "* Supervised problem: we are given both the features and the target\n",
    "* Regression problem: the target is a continous variable, in this case ranging from 0-100\n",
    "\n",
    "During training, we want the model to learn the relationship between the features and the score so we give it both the features and the answer. Then, to test how well the model has learned, we evaluate it on a testing set where it has never seen the answers!\n",
    "\n",
    "## Machine Learning Workflow\n",
    "\n",
    "Although the exact implementation details can vary, the general structure of a machine learning project stays relatively constant:\n",
    "\n",
    "    1) Data cleaning and formatting\n",
    "    2) Exploratory data analysis\n",
    "    3) Feature engineering and selection\n",
    "    4) Establish a baseline and compare several machine learning models on a performance metric\n",
    "    5) Perform hyperparameter tuning on the best model to optimize it for the problem\n",
    "    6) Evaluate the best model on the testing set\n",
    "    7) Interpret the model results to the extent possible\n",
    "    8) Draw conclusions and write a well-documented report\n",
    "\n",
    "Setting up the structure of the pipeline ahead of time lets us see how one step flows into the other. However, the machine learning pipeline is an iterative procedure and so we don't always follow these steps in a linear fashion. We may revisit a previous step based on results from further down the pipeline. For example, while we may perform feature selection before building any models, we may use the modeling results to go back and select a different set of features. Or, the modeling may turn up unexpected results that mean we want to explore our data from another angle. Generally, you have to complete one step before moving on to the next, but don't feel like once you have finished one step the first time, you cannot go back and make improvements!\n",
    "\n",
    "The objective of this notebook is to show how all the different data science practices come together to form a complete project. The focus is more on the implementations of the methods rather than explaining them at a low-level, but have provided resources for those who want to go deeper. A good book for learning the basics and implementing machine learning practices in Python, check out Hands-On Machine Learning with Scikit-Learn and Tensorflow by Aurelion Geron.\n",
    "\n",
    "With this outline in place to guide us, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "We will use the standard data science and machine learning libraries: numpy, pandas, and scikit-learn. We also use matplotlib and seaborn for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# No warnings about setting value on copy of slice, i.e. no annoying pink boxes\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Display up to 60 columns of a dataframe\n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "# Matplotlib visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "# Internal ipython tool for setting figure size\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# Seaborn for visualization\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 2)\n",
    "\n",
    "# Splitting data into training and testing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Formatting\n",
    "\n",
    "## Load in the Data and Examine\n",
    "\n",
    "We will be loading our data into a pandas dataframe, one of the most useful data structures for data science. Think of it as a spreadsheet within Python that we can easily manipulate, clean, and visualize. [Pandas has many methods](http://pandas.pydata.org/pandas-docs/stable/) to help make the data science/machine learning pipeline as smooth as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ismahfaris\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MachineIdentifier</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>EngineVersion</th>\n",
       "      <th>AppVersion</th>\n",
       "      <th>AvSigVersion</th>\n",
       "      <th>IsBeta</th>\n",
       "      <th>RtpStateBitfield</th>\n",
       "      <th>IsSxsPassiveMode</th>\n",
       "      <th>DefaultBrowsersIdentifier</th>\n",
       "      <th>AVProductStatesIdentifier</th>\n",
       "      <th>AVProductsInstalled</th>\n",
       "      <th>AVProductsEnabled</th>\n",
       "      <th>HasTpm</th>\n",
       "      <th>CountryIdentifier</th>\n",
       "      <th>CityIdentifier</th>\n",
       "      <th>OrganizationIdentifier</th>\n",
       "      <th>GeoNameIdentifier</th>\n",
       "      <th>LocaleEnglishNameIdentifier</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Processor</th>\n",
       "      <th>OsVer</th>\n",
       "      <th>OsBuild</th>\n",
       "      <th>OsSuite</th>\n",
       "      <th>OsPlatformSubRelease</th>\n",
       "      <th>OsBuildLab</th>\n",
       "      <th>SkuEdition</th>\n",
       "      <th>IsProtected</th>\n",
       "      <th>AutoSampleOptIn</th>\n",
       "      <th>PuaMode</th>\n",
       "      <th>SMode</th>\n",
       "      <th>...</th>\n",
       "      <th>Census_InternalBatteryNumberOfCharges</th>\n",
       "      <th>Census_OSVersion</th>\n",
       "      <th>Census_OSArchitecture</th>\n",
       "      <th>Census_OSBranch</th>\n",
       "      <th>Census_OSBuildNumber</th>\n",
       "      <th>Census_OSBuildRevision</th>\n",
       "      <th>Census_OSEdition</th>\n",
       "      <th>Census_OSSkuName</th>\n",
       "      <th>Census_OSInstallTypeName</th>\n",
       "      <th>Census_OSInstallLanguageIdentifier</th>\n",
       "      <th>Census_OSUILocaleIdentifier</th>\n",
       "      <th>Census_OSWUAutoUpdateOptionsName</th>\n",
       "      <th>Census_IsPortableOperatingSystem</th>\n",
       "      <th>Census_GenuineStateName</th>\n",
       "      <th>Census_ActivationChannel</th>\n",
       "      <th>Census_IsFlightingInternal</th>\n",
       "      <th>Census_IsFlightsDisabled</th>\n",
       "      <th>Census_FlightRing</th>\n",
       "      <th>Census_ThresholdOptIn</th>\n",
       "      <th>Census_FirmwareManufacturerIdentifier</th>\n",
       "      <th>Census_FirmwareVersionIdentifier</th>\n",
       "      <th>Census_IsSecureBootEnabled</th>\n",
       "      <th>Census_IsWIMBootEnabled</th>\n",
       "      <th>Census_IsVirtualDevice</th>\n",
       "      <th>Census_IsTouchEnabled</th>\n",
       "      <th>Census_IsPenCapable</th>\n",
       "      <th>Census_IsAlwaysOnAlwaysConnectedCapable</th>\n",
       "      <th>Wdft_IsGamer</th>\n",
       "      <th>Wdft_RegionIdentifier</th>\n",
       "      <th>HasDetections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000028988387b115f69f31a3bf04f09</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.15100.1</td>\n",
       "      <td>4.18.1807.18075</td>\n",
       "      <td>1.273.1735.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>128035.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>171</td>\n",
       "      <td>windows10</td>\n",
       "      <td>x64</td>\n",
       "      <td>10.0.0.0</td>\n",
       "      <td>17134</td>\n",
       "      <td>256</td>\n",
       "      <td>rs4</td>\n",
       "      <td>17134.1.amd64fre.rs4_release.180410-1804</td>\n",
       "      <td>Pro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.294967e+09</td>\n",
       "      <td>10.0.17134.165</td>\n",
       "      <td>amd64</td>\n",
       "      <td>rs4_release</td>\n",
       "      <td>17134</td>\n",
       "      <td>165</td>\n",
       "      <td>Professional</td>\n",
       "      <td>PROFESSIONAL</td>\n",
       "      <td>UUPUpgrade</td>\n",
       "      <td>26.0</td>\n",
       "      <td>119</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "      <td>IS_GENUINE</td>\n",
       "      <td>Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>628.0</td>\n",
       "      <td>36144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000007535c3f730efa9ea0b7ef1bd645</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.14600.4</td>\n",
       "      <td>4.13.17134.1</td>\n",
       "      <td>1.263.48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>64</td>\n",
       "      <td>windows10</td>\n",
       "      <td>x64</td>\n",
       "      <td>10.0.0.0</td>\n",
       "      <td>17134</td>\n",
       "      <td>256</td>\n",
       "      <td>rs4</td>\n",
       "      <td>17134.1.amd64fre.rs4_release.180410-1804</td>\n",
       "      <td>Pro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>10.0.17134.1</td>\n",
       "      <td>amd64</td>\n",
       "      <td>rs4_release</td>\n",
       "      <td>17134</td>\n",
       "      <td>1</td>\n",
       "      <td>Professional</td>\n",
       "      <td>PROFESSIONAL</td>\n",
       "      <td>IBSClean</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "      <td>OFFLINE</td>\n",
       "      <td>Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOT_SET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>628.0</td>\n",
       "      <td>57858.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000007905a28d863f6d0d597892cd692</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.15100.1</td>\n",
       "      <td>4.18.1807.18075</td>\n",
       "      <td>1.273.1341.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>153579.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>49</td>\n",
       "      <td>windows10</td>\n",
       "      <td>x64</td>\n",
       "      <td>10.0.0.0</td>\n",
       "      <td>17134</td>\n",
       "      <td>768</td>\n",
       "      <td>rs4</td>\n",
       "      <td>17134.1.amd64fre.rs4_release.180410-1804</td>\n",
       "      <td>Home</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.294967e+09</td>\n",
       "      <td>10.0.17134.165</td>\n",
       "      <td>amd64</td>\n",
       "      <td>rs4_release</td>\n",
       "      <td>17134</td>\n",
       "      <td>165</td>\n",
       "      <td>Core</td>\n",
       "      <td>CORE</td>\n",
       "      <td>UUPUpgrade</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30</td>\n",
       "      <td>FullAuto</td>\n",
       "      <td>0</td>\n",
       "      <td>IS_GENUINE</td>\n",
       "      <td>OEM:NONSLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.0</td>\n",
       "      <td>52682.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00000b11598a75ea8ba1beea8459149f</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.15100.1</td>\n",
       "      <td>4.18.1807.18075</td>\n",
       "      <td>1.273.1527.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>20710.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.0</td>\n",
       "      <td>115</td>\n",
       "      <td>windows10</td>\n",
       "      <td>x64</td>\n",
       "      <td>10.0.0.0</td>\n",
       "      <td>17134</td>\n",
       "      <td>256</td>\n",
       "      <td>rs4</td>\n",
       "      <td>17134.1.amd64fre.rs4_release.180410-1804</td>\n",
       "      <td>Pro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.294967e+09</td>\n",
       "      <td>10.0.17134.228</td>\n",
       "      <td>amd64</td>\n",
       "      <td>rs4_release</td>\n",
       "      <td>17134</td>\n",
       "      <td>228</td>\n",
       "      <td>Professional</td>\n",
       "      <td>PROFESSIONAL</td>\n",
       "      <td>UUPUpgrade</td>\n",
       "      <td>17.0</td>\n",
       "      <td>64</td>\n",
       "      <td>FullAuto</td>\n",
       "      <td>0</td>\n",
       "      <td>IS_GENUINE</td>\n",
       "      <td>OEM:NONSLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355.0</td>\n",
       "      <td>20050.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000014a5f00daa18e76b81417eeb99fc</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.15100.1</td>\n",
       "      <td>4.18.1807.18075</td>\n",
       "      <td>1.273.1379.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53447.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>37376.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.0</td>\n",
       "      <td>75</td>\n",
       "      <td>windows10</td>\n",
       "      <td>x64</td>\n",
       "      <td>10.0.0.0</td>\n",
       "      <td>17134</td>\n",
       "      <td>768</td>\n",
       "      <td>rs4</td>\n",
       "      <td>17134.1.amd64fre.rs4_release.180410-1804</td>\n",
       "      <td>Home</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.0.17134.191</td>\n",
       "      <td>amd64</td>\n",
       "      <td>rs4_release</td>\n",
       "      <td>17134</td>\n",
       "      <td>191</td>\n",
       "      <td>Core</td>\n",
       "      <td>CORE</td>\n",
       "      <td>Update</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31</td>\n",
       "      <td>FullAuto</td>\n",
       "      <td>0</td>\n",
       "      <td>IS_GENUINE</td>\n",
       "      <td>Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>19844.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MachineIdentifier   ProductName EngineVersion  \\\n",
       "0  0000028988387b115f69f31a3bf04f09  win8defender   1.1.15100.1   \n",
       "1  000007535c3f730efa9ea0b7ef1bd645  win8defender   1.1.14600.4   \n",
       "2  000007905a28d863f6d0d597892cd692  win8defender   1.1.15100.1   \n",
       "3  00000b11598a75ea8ba1beea8459149f  win8defender   1.1.15100.1   \n",
       "4  000014a5f00daa18e76b81417eeb99fc  win8defender   1.1.15100.1   \n",
       "\n",
       "        AppVersion  AvSigVersion  IsBeta  RtpStateBitfield  IsSxsPassiveMode  \\\n",
       "0  4.18.1807.18075  1.273.1735.0       0               7.0                 0   \n",
       "1     4.13.17134.1    1.263.48.0       0               7.0                 0   \n",
       "2  4.18.1807.18075  1.273.1341.0       0               7.0                 0   \n",
       "3  4.18.1807.18075  1.273.1527.0       0               7.0                 0   \n",
       "4  4.18.1807.18075  1.273.1379.0       0               7.0                 0   \n",
       "\n",
       "   DefaultBrowsersIdentifier  AVProductStatesIdentifier  AVProductsInstalled  \\\n",
       "0                        NaN                    53447.0                  1.0   \n",
       "1                        NaN                    53447.0                  1.0   \n",
       "2                        NaN                    53447.0                  1.0   \n",
       "3                        NaN                    53447.0                  1.0   \n",
       "4                        NaN                    53447.0                  1.0   \n",
       "\n",
       "   AVProductsEnabled  HasTpm  CountryIdentifier  CityIdentifier  \\\n",
       "0                1.0       1                 29        128035.0   \n",
       "1                1.0       1                 93          1482.0   \n",
       "2                1.0       1                 86        153579.0   \n",
       "3                1.0       1                 88         20710.0   \n",
       "4                1.0       1                 18         37376.0   \n",
       "\n",
       "   OrganizationIdentifier  GeoNameIdentifier  LocaleEnglishNameIdentifier  \\\n",
       "0                    18.0               35.0                          171   \n",
       "1                    18.0              119.0                           64   \n",
       "2                    18.0               64.0                           49   \n",
       "3                     NaN              117.0                          115   \n",
       "4                     NaN              277.0                           75   \n",
       "\n",
       "    Platform Processor     OsVer  OsBuild  OsSuite OsPlatformSubRelease  \\\n",
       "0  windows10       x64  10.0.0.0    17134      256                  rs4   \n",
       "1  windows10       x64  10.0.0.0    17134      256                  rs4   \n",
       "2  windows10       x64  10.0.0.0    17134      768                  rs4   \n",
       "3  windows10       x64  10.0.0.0    17134      256                  rs4   \n",
       "4  windows10       x64  10.0.0.0    17134      768                  rs4   \n",
       "\n",
       "                                 OsBuildLab SkuEdition  IsProtected  \\\n",
       "0  17134.1.amd64fre.rs4_release.180410-1804        Pro          1.0   \n",
       "1  17134.1.amd64fre.rs4_release.180410-1804        Pro          1.0   \n",
       "2  17134.1.amd64fre.rs4_release.180410-1804       Home          1.0   \n",
       "3  17134.1.amd64fre.rs4_release.180410-1804        Pro          1.0   \n",
       "4  17134.1.amd64fre.rs4_release.180410-1804       Home          1.0   \n",
       "\n",
       "   AutoSampleOptIn PuaMode  SMode  ...  Census_InternalBatteryNumberOfCharges  \\\n",
       "0                0     NaN    0.0  ...                           4.294967e+09   \n",
       "1                0     NaN    0.0  ...                           1.000000e+00   \n",
       "2                0     NaN    0.0  ...                           4.294967e+09   \n",
       "3                0     NaN    0.0  ...                           4.294967e+09   \n",
       "4                0     NaN    0.0  ...                           0.000000e+00   \n",
       "\n",
       "  Census_OSVersion  Census_OSArchitecture  Census_OSBranch  \\\n",
       "0   10.0.17134.165                  amd64      rs4_release   \n",
       "1     10.0.17134.1                  amd64      rs4_release   \n",
       "2   10.0.17134.165                  amd64      rs4_release   \n",
       "3   10.0.17134.228                  amd64      rs4_release   \n",
       "4   10.0.17134.191                  amd64      rs4_release   \n",
       "\n",
       "  Census_OSBuildNumber Census_OSBuildRevision  Census_OSEdition  \\\n",
       "0                17134                    165      Professional   \n",
       "1                17134                      1      Professional   \n",
       "2                17134                    165              Core   \n",
       "3                17134                    228      Professional   \n",
       "4                17134                    191              Core   \n",
       "\n",
       "   Census_OSSkuName  Census_OSInstallTypeName  \\\n",
       "0      PROFESSIONAL                UUPUpgrade   \n",
       "1      PROFESSIONAL                  IBSClean   \n",
       "2              CORE                UUPUpgrade   \n",
       "3      PROFESSIONAL                UUPUpgrade   \n",
       "4              CORE                    Update   \n",
       "\n",
       "   Census_OSInstallLanguageIdentifier  Census_OSUILocaleIdentifier  \\\n",
       "0                                26.0                          119   \n",
       "1                                 8.0                           31   \n",
       "2                                 7.0                           30   \n",
       "3                                17.0                           64   \n",
       "4                                 8.0                           31   \n",
       "\n",
       "  Census_OSWUAutoUpdateOptionsName  Census_IsPortableOperatingSystem  \\\n",
       "0                          UNKNOWN                                 0   \n",
       "1                          UNKNOWN                                 0   \n",
       "2                         FullAuto                                 0   \n",
       "3                         FullAuto                                 0   \n",
       "4                         FullAuto                                 0   \n",
       "\n",
       "  Census_GenuineStateName  Census_ActivationChannel  \\\n",
       "0              IS_GENUINE                    Retail   \n",
       "1                 OFFLINE                    Retail   \n",
       "2              IS_GENUINE                OEM:NONSLP   \n",
       "3              IS_GENUINE                OEM:NONSLP   \n",
       "4              IS_GENUINE                    Retail   \n",
       "\n",
       "   Census_IsFlightingInternal  Census_IsFlightsDisabled Census_FlightRing  \\\n",
       "0                         NaN                       0.0            Retail   \n",
       "1                         NaN                       0.0           NOT_SET   \n",
       "2                         NaN                       0.0            Retail   \n",
       "3                         NaN                       0.0            Retail   \n",
       "4                         0.0                       0.0            Retail   \n",
       "\n",
       "   Census_ThresholdOptIn  Census_FirmwareManufacturerIdentifier  \\\n",
       "0                    NaN                                  628.0   \n",
       "1                    NaN                                  628.0   \n",
       "2                    NaN                                  142.0   \n",
       "3                    NaN                                  355.0   \n",
       "4                    0.0                                  355.0   \n",
       "\n",
       "   Census_FirmwareVersionIdentifier Census_IsSecureBootEnabled  \\\n",
       "0                           36144.0                          0   \n",
       "1                           57858.0                          0   \n",
       "2                           52682.0                          0   \n",
       "3                           20050.0                          0   \n",
       "4                           19844.0                          0   \n",
       "\n",
       "  Census_IsWIMBootEnabled  Census_IsVirtualDevice Census_IsTouchEnabled  \\\n",
       "0                     NaN                     0.0                     0   \n",
       "1                     NaN                     0.0                     0   \n",
       "2                     NaN                     0.0                     0   \n",
       "3                     NaN                     0.0                     0   \n",
       "4                     0.0                     0.0                     0   \n",
       "\n",
       "  Census_IsPenCapable Census_IsAlwaysOnAlwaysConnectedCapable  Wdft_IsGamer  \\\n",
       "0                   0                                     0.0           0.0   \n",
       "1                   0                                     0.0           0.0   \n",
       "2                   0                                     0.0           0.0   \n",
       "3                   0                                     0.0           0.0   \n",
       "4                   0                                     0.0           0.0   \n",
       "\n",
       "   Wdft_RegionIdentifier HasDetections  \n",
       "0                   10.0             0  \n",
       "1                    8.0             0  \n",
       "2                    3.0             0  \n",
       "3                    3.0             1  \n",
       "4                    1.0             1  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data into a dataframe \n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Display top of dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because data is huge, for purpose of practice, will reduce it to 5% sample of the whole population for the time being.\n",
    "df = data.sample(frac=0.05, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing a Large Dataset\n",
    "\n",
    "The size of the training and testing data is 9 million and 8 million rows, respectively. There are 81 features in total, with 52 being categorical, 23 of which are encoded numerically to protect the privacy of the information. Taking into consideration the large dataset, several factors helped reduce the burden of working with large datasets.\n",
    "Understanding datatypes (dtypes). When the training data is fully loaded into working memory (DRAM), Pandas takes approximately 17–20GB without using optimal dtypes. With the help of dataquest.io, I was able to reduce this all the way down significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.40 MB\n",
      "3.40 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [before, after]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're going to be calculating memory usage a lot,\n",
    "# so we'll create a function to save us some time!\n",
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)\n",
    "\n",
    "df_int = df.select_dtypes(include=['int'])\n",
    "converted_int = df_int.apply(pd.to_numeric,downcast='unsigned')\n",
    "\n",
    "print(mem_usage(df_int))\n",
    "print(mem_usage(converted_int))\n",
    "\n",
    "compare_ints = pd.concat([df_int.dtypes,converted_int.dtypes],axis=1)\n",
    "compare_ints.columns = ['before','after']\n",
    "compare_ints.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125.92 MB\n",
      "64.66 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [before, after]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_float = df.select_dtypes(include=['float'])\n",
    "converted_float = df_float.apply(pd.to_numeric,downcast='float')\n",
    "\n",
    "print(mem_usage(df_float))\n",
    "print(mem_usage(converted_float))\n",
    "\n",
    "compare_floats = pd.concat([df_int.dtypes,converted_int.dtypes],axis=1)\n",
    "compare_floats.columns = ['before','after']\n",
    "compare_floats.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19974.80 MB\n",
      "940.90 MB\n"
     ]
    }
   ],
   "source": [
    "optimized_df = df.copy()\n",
    "optimized_df[converted_int.columns] = converted_int\n",
    "optimized_df[converted_float.columns] = converted_float\n",
    "print(mem_usage(data))\n",
    "print(mem_usage(optimized_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MachineIdentifier</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>EngineVersion</th>\n",
       "      <th>AppVersion</th>\n",
       "      <th>AvSigVersion</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Processor</th>\n",
       "      <th>OsVer</th>\n",
       "      <th>OsPlatformSubRelease</th>\n",
       "      <th>OsBuildLab</th>\n",
       "      <th>SkuEdition</th>\n",
       "      <th>PuaMode</th>\n",
       "      <th>SmartScreen</th>\n",
       "      <th>Census_MDC2FormFactor</th>\n",
       "      <th>Census_DeviceFamily</th>\n",
       "      <th>Census_ProcessorClass</th>\n",
       "      <th>Census_PrimaryDiskTypeName</th>\n",
       "      <th>Census_ChassisTypeName</th>\n",
       "      <th>Census_PowerPlatformRoleName</th>\n",
       "      <th>Census_InternalBatteryType</th>\n",
       "      <th>Census_OSVersion</th>\n",
       "      <th>Census_OSArchitecture</th>\n",
       "      <th>Census_OSBranch</th>\n",
       "      <th>Census_OSEdition</th>\n",
       "      <th>Census_OSSkuName</th>\n",
       "      <th>Census_OSInstallTypeName</th>\n",
       "      <th>Census_OSWUAutoUpdateOptionsName</th>\n",
       "      <th>Census_GenuineStateName</th>\n",
       "      <th>Census_ActivationChannel</th>\n",
       "      <th>Census_FlightRing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446072</td>\n",
       "      <td>446074</td>\n",
       "      <td>117</td>\n",
       "      <td>287311</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>1839</td>\n",
       "      <td>445407</td>\n",
       "      <td>446043</td>\n",
       "      <td>446072</td>\n",
       "      <td>129379</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "      <td>446074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>435072</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>91</td>\n",
       "      <td>6254</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>457</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>295</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>fd8655bbe570f2e8f886d54f4730a109</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.15200.1</td>\n",
       "      <td>4.18.1807.18075</td>\n",
       "      <td>1.273.1420.0</td>\n",
       "      <td>windows10</td>\n",
       "      <td>x64</td>\n",
       "      <td>10.0.0.0</td>\n",
       "      <td>rs4</td>\n",
       "      <td>17134.1.amd64fre.rs4_release.180410-1804</td>\n",
       "      <td>Home</td>\n",
       "      <td>on</td>\n",
       "      <td>RequireAdmin</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>Windows.Desktop</td>\n",
       "      <td>mid</td>\n",
       "      <td>HDD</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>lion</td>\n",
       "      <td>10.0.17134.228</td>\n",
       "      <td>amd64</td>\n",
       "      <td>rs4_release</td>\n",
       "      <td>Core</td>\n",
       "      <td>CORE</td>\n",
       "      <td>UUPUpgrade</td>\n",
       "      <td>FullAuto</td>\n",
       "      <td>IS_GENUINE</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>4</td>\n",
       "      <td>441276</td>\n",
       "      <td>192744</td>\n",
       "      <td>256705</td>\n",
       "      <td>5098</td>\n",
       "      <td>430770</td>\n",
       "      <td>405283</td>\n",
       "      <td>431438</td>\n",
       "      <td>195851</td>\n",
       "      <td>183017</td>\n",
       "      <td>275896</td>\n",
       "      <td>117</td>\n",
       "      <td>216008</td>\n",
       "      <td>286458</td>\n",
       "      <td>445380</td>\n",
       "      <td>1014</td>\n",
       "      <td>290410</td>\n",
       "      <td>262888</td>\n",
       "      <td>309415</td>\n",
       "      <td>101604</td>\n",
       "      <td>70757</td>\n",
       "      <td>405236</td>\n",
       "      <td>200550</td>\n",
       "      <td>173258</td>\n",
       "      <td>173255</td>\n",
       "      <td>130496</td>\n",
       "      <td>197895</td>\n",
       "      <td>393675</td>\n",
       "      <td>236574</td>\n",
       "      <td>417908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MachineIdentifier   ProductName EngineVersion  \\\n",
       "count                             446074        446074        446074   \n",
       "unique                            435072             4            53   \n",
       "top     fd8655bbe570f2e8f886d54f4730a109  win8defender   1.1.15200.1   \n",
       "freq                                   4        441276        192744   \n",
       "\n",
       "             AppVersion  AvSigVersion   Platform Processor     OsVer  \\\n",
       "count            446074        446074     446074    446074    446074   \n",
       "unique               91          6254          4         3        14   \n",
       "top     4.18.1807.18075  1.273.1420.0  windows10       x64  10.0.0.0   \n",
       "freq             256705          5098     430770    405283    431438   \n",
       "\n",
       "       OsPlatformSubRelease                                OsBuildLab  \\\n",
       "count                446074                                    446072   \n",
       "unique                    9                                       457   \n",
       "top                     rs4  17134.1.amd64fre.rs4_release.180410-1804   \n",
       "freq                 195851                                    183017   \n",
       "\n",
       "       SkuEdition PuaMode   SmartScreen Census_MDC2FormFactor  \\\n",
       "count      446074     117        287311                446074   \n",
       "unique          8       1            12                    12   \n",
       "top          Home      on  RequireAdmin              Notebook   \n",
       "freq       275896     117        216008                286458   \n",
       "\n",
       "       Census_DeviceFamily Census_ProcessorClass Census_PrimaryDiskTypeName  \\\n",
       "count               446074                  1839                     445407   \n",
       "unique                   2                     3                          4   \n",
       "top        Windows.Desktop                   mid                        HDD   \n",
       "freq                445380                  1014                     290410   \n",
       "\n",
       "       Census_ChassisTypeName Census_PowerPlatformRoleName  \\\n",
       "count                  446043                       446072   \n",
       "unique                     34                            9   \n",
       "top                  Notebook                       Mobile   \n",
       "freq                   262888                       309415   \n",
       "\n",
       "       Census_InternalBatteryType Census_OSVersion Census_OSArchitecture  \\\n",
       "count                      129379           446074                446074   \n",
       "unique                         31              295                     3   \n",
       "top                          lion   10.0.17134.228                 amd64   \n",
       "freq                       101604            70757                405236   \n",
       "\n",
       "       Census_OSBranch Census_OSEdition Census_OSSkuName  \\\n",
       "count           446074           446074           446074   \n",
       "unique              15               22               21   \n",
       "top        rs4_release             Core             CORE   \n",
       "freq            200550           173258           173255   \n",
       "\n",
       "       Census_OSInstallTypeName Census_OSWUAutoUpdateOptionsName  \\\n",
       "count                    446074                           446074   \n",
       "unique                        9                                6   \n",
       "top                  UUPUpgrade                         FullAuto   \n",
       "freq                     130496                           197895   \n",
       "\n",
       "       Census_GenuineStateName Census_ActivationChannel Census_FlightRing  \n",
       "count                   446074                   446074            446074  \n",
       "unique                       4                        6                 7  \n",
       "top                 IS_GENUINE                   Retail            Retail  \n",
       "freq                    393675                   236574            417908  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obj = df.select_dtypes(include=['object']).copy()\n",
    "df_obj.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821.79 MB\n",
      "55.57 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>object</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          before  after\n",
       "object      30.0      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1\n",
       "category     NaN      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_obj = pd.DataFrame()\n",
    "for col in df_obj.columns:\n",
    "    num_unique_values = len(df_obj[col].unique())\n",
    "    num_total_values = len(df_obj[col])\n",
    "    if num_unique_values / num_total_values < 0.5:\n",
    "        converted_obj.loc[:,col] = df_obj[col].astype('category')\n",
    "    else:\n",
    "        converted_obj.loc[:,col] = df_obj[col]\n",
    "        \n",
    "print(mem_usage(df_obj))\n",
    "print(mem_usage(converted_obj))\n",
    "compare_obj = pd.concat([df_obj.dtypes,converted_obj.dtypes],axis=1)\n",
    "compare_obj.columns = ['before','after']\n",
    "compare_obj.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19974.80 MB\n",
      "174.69 MB\n"
     ]
    }
   ],
   "source": [
    "optimized_df[converted_obj.columns] = converted_obj\n",
    "mem_new = mem_usage(optimized_df)\n",
    "mem_old = mem_usage(data)\n",
    "\n",
    "print(mem_old)\n",
    "print(mem_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory reduction: 99.13%\n"
     ]
    }
   ],
   "source": [
    "print(f'Memory reduction: {(1-float(mem_new[:-2])/float(mem_old[:-2]))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types and Missing Values\n",
    "\n",
    "The dataframe.info method is a quick way to assess the data by displaying the data types of each column and the number of non-missing values. In this case, everything seems to be in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 446074 entries, 678733 to 7310237\n",
      "Data columns (total 83 columns):\n",
      "MachineIdentifier                                    446074 non-null object\n",
      "ProductName                                          446074 non-null category\n",
      "EngineVersion                                        446074 non-null category\n",
      "AppVersion                                           446074 non-null category\n",
      "AvSigVersion                                         446074 non-null category\n",
      "IsBeta                                               446074 non-null int64\n",
      "RtpStateBitfield                                     444460 non-null float32\n",
      "IsSxsPassiveMode                                     446074 non-null int64\n",
      "DefaultBrowsersIdentifier                            21626 non-null float32\n",
      "AVProductStatesIdentifier                            444298 non-null float32\n",
      "AVProductsInstalled                                  444298 non-null float32\n",
      "AVProductsEnabled                                    444298 non-null float32\n",
      "HasTpm                                               446074 non-null int64\n",
      "CountryIdentifier                                    446074 non-null int64\n",
      "CityIdentifier                                       429901 non-null float32\n",
      "OrganizationIdentifier                               308396 non-null float32\n",
      "GeoNameIdentifier                                    446060 non-null float32\n",
      "LocaleEnglishNameIdentifier                          446074 non-null int64\n",
      "Platform                                             446074 non-null category\n",
      "Processor                                            446074 non-null category\n",
      "OsVer                                                446074 non-null category\n",
      "OsBuild                                              446074 non-null int64\n",
      "OsSuite                                              446074 non-null int64\n",
      "OsPlatformSubRelease                                 446074 non-null category\n",
      "OsBuildLab                                           446072 non-null category\n",
      "SkuEdition                                           446074 non-null category\n",
      "IsProtected                                          444304 non-null float32\n",
      "AutoSampleOptIn                                      446074 non-null int64\n",
      "PuaMode                                              117 non-null category\n",
      "SMode                                                419230 non-null float32\n",
      "IeVerIdentifier                                      443051 non-null float32\n",
      "SmartScreen                                          287311 non-null category\n",
      "Firewall                                             441470 non-null float32\n",
      "UacLuaenable                                         445561 non-null float32\n",
      "Census_MDC2FormFactor                                446074 non-null category\n",
      "Census_DeviceFamily                                  446074 non-null category\n",
      "Census_OEMNameIdentifier                             441362 non-null float32\n",
      "Census_OEMModelIdentifier                            441042 non-null float32\n",
      "Census_ProcessorCoreCount                            443976 non-null float32\n",
      "Census_ProcessorManufacturerIdentifier               443976 non-null float32\n",
      "Census_ProcessorModelIdentifier                      443973 non-null float32\n",
      "Census_ProcessorClass                                1839 non-null category\n",
      "Census_PrimaryDiskTotalCapacity                      443426 non-null float32\n",
      "Census_PrimaryDiskTypeName                           445407 non-null category\n",
      "Census_SystemVolumeTotalCapacity                     443426 non-null float32\n",
      "Census_HasOpticalDiskDrive                           446074 non-null int64\n",
      "Census_TotalPhysicalRAM                              442044 non-null float32\n",
      "Census_ChassisTypeName                               446043 non-null category\n",
      "Census_InternalPrimaryDiagonalDisplaySizeInInches    443704 non-null float32\n",
      "Census_InternalPrimaryDisplayResolutionHorizontal    443712 non-null float32\n",
      "Census_InternalPrimaryDisplayResolutionVertical      443712 non-null float32\n",
      "Census_PowerPlatformRoleName                         446072 non-null category\n",
      "Census_InternalBatteryType                           129379 non-null category\n",
      "Census_InternalBatteryNumberOfCharges                432655 non-null float32\n",
      "Census_OSVersion                                     446074 non-null category\n",
      "Census_OSArchitecture                                446074 non-null category\n",
      "Census_OSBranch                                      446074 non-null category\n",
      "Census_OSBuildNumber                                 446074 non-null int64\n",
      "Census_OSBuildRevision                               446074 non-null int64\n",
      "Census_OSEdition                                     446074 non-null category\n",
      "Census_OSSkuName                                     446074 non-null category\n",
      "Census_OSInstallTypeName                             446074 non-null category\n",
      "Census_OSInstallLanguageIdentifier                   443113 non-null float32\n",
      "Census_OSUILocaleIdentifier                          446074 non-null int64\n",
      "Census_OSWUAutoUpdateOptionsName                     446074 non-null category\n",
      "Census_IsPortableOperatingSystem                     446074 non-null int64\n",
      "Census_GenuineStateName                              446074 non-null category\n",
      "Census_ActivationChannel                             446074 non-null category\n",
      "Census_IsFlightingInternal                           75594 non-null float32\n",
      "Census_IsFlightsDisabled                             437986 non-null float32\n",
      "Census_FlightRing                                    446074 non-null category\n",
      "Census_ThresholdOptIn                                163010 non-null float32\n",
      "Census_FirmwareManufacturerIdentifier                436919 non-null float32\n",
      "Census_FirmwareVersionIdentifier                     438046 non-null float32\n",
      "Census_IsSecureBootEnabled                           446074 non-null int64\n",
      "Census_IsWIMBootEnabled                              163433 non-null float32\n",
      "Census_IsVirtualDevice                               445263 non-null float32\n",
      "Census_IsTouchEnabled                                446074 non-null int64\n",
      "Census_IsPenCapable                                  446074 non-null int64\n",
      "Census_IsAlwaysOnAlwaysConnectedCapable              442546 non-null float32\n",
      "Wdft_IsGamer                                         430924 non-null float32\n",
      "Wdft_RegionIdentifier                                430924 non-null float32\n",
      "HasDetections                                        446074 non-null int64\n",
      "dtypes: category(29), float32(36), int64(17), object(1)\n",
      "memory usage: 139.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# See the column data types and non-missing values\n",
    "optimized_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all occurrences of Not Available with numpy not a number\n",
    "optimized_df = optimized_df.replace({'Not Available': np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "Now that we have the correct column datatypes, we can start analysis by looking at the percentage of missing values in each column. Missing values are fine when we do Exploratory Data Analysis, but they will have to be filled in for machine learning methods.\n",
    "\n",
    "Following is a function that calculates the number of missing values and the percentage of the total values that are missing for each column. I found this function online under the [Stack Overflow forum!](https://stackoverflow.com/a/39734251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column\n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(optimized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Although we want to be careful to not discard information and should be careful when dropping columns, if a column has a high percentage of missing values, then it probably will not be of much use.\n",
    "\n",
    "What columns to retain may be a little arbitrary [(here is a discussion)](https://discuss.analyticsvidhya.com/t/what-should-be-the-allowed-percentage-of-missing-values/2456), but for this project, we will remove any columns with more than 50% missing values. In general, be careful about dropping any information because even if it is not there for all the observations, it may still be useful for predicting the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns with > 50% missing\n",
    "missing_df = missing_values_table(optimized_df);\n",
    "missing_columns = list(missing_df[missing_df['% of Total Values'] > 50].index)\n",
    "print('We will remove %d columns.' % len(missing_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns\n",
    "optimized_df = optimized_df.drop(columns = list(missing_columns))\n",
    "\n",
    "# For older versions of pandas (https://github.com/pandas-dev/pandas/issues/19078)\n",
    "# data = data.drop(list(missing_columns), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our target HasDetections is categorical in nature with either a 1 or 0, lets try to analyse & explore more on how the different features may relate to it. I came across this [algorithm for quantitative/categorical analysis](https://towardsdatascience.com/a-starter-pack-to-exploratory-data-analysis-with-python-pandas-seaborn-and-scikit-learn-a77889485baf#249d) that may prove useful in our exploratory data analysis. In this case, we will use the categorical summarized algorithm prepared for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_summarized(dataframe, x=None, y=None, hue=None, palette='Set1', verbose=True):\n",
    "    '''\n",
    "    Helper function that gives a quick summary of a given column of categorical data\n",
    "    Arguments\n",
    "    =========\n",
    "    dataframe: pandas dataframe\n",
    "    x: str. horizontal axis to plot the labels of categorical data, y would be the count\n",
    "    y: str. vertical axis to plot the labels of categorical data, x would be the count\n",
    "    hue: str. if you want to compare it another variable (usually the target variable)\n",
    "    palette: array-like. Colour of the plot\n",
    "    Returns\n",
    "    =======\n",
    "    Quick Stats of the data and also the count plot\n",
    "    '''\n",
    "    if x == None:\n",
    "        column_interested = y\n",
    "    else:\n",
    "        column_interested = x\n",
    "    series = dataframe[column_interested]\n",
    "    print(series.describe())\n",
    "    print('mode: ', series.mode())\n",
    "    if verbose:\n",
    "        print('='*80)\n",
    "        print(series.value_counts())\n",
    "\n",
    "    sns.countplot(x=x, y=y, hue=hue, data=dataframe, palette=palette)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the score \n",
    "optimized_df = optimized_df.rename(columns = {'HasDetections': 'score'})\n",
    "explore = optimized_df.sample(frac =.01)\n",
    "# Target Variable: HasDetections (score)\n",
    "c_palette = ['tab:blue', 'tab:orange']\n",
    "categorical_summarized(explore, y = 'score', palette=c_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Variable: Firewall\n",
    "categorical_summarized(explore, y = 'Firewall', hue='score', palette=c_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Variable: Platform\n",
    "categorical_summarized(explore, y = 'Platform', hue='score', palette=c_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The platform & firewall does not seem to make as significant a difference in the distribution of the score. Nonetheless, it might make sense to include them as variables.\n",
    "\n",
    "### Correlations between Features and Target\n",
    "\n",
    "In order to quantify correlations between the features (variables) and the target, we can calculate the [Pearson correlation coefficient](http://www.statisticshowto.com/probability-and-statistics/correlation-coefficient-formula/). This is a measure of the strength and direction of a linear relationship between two variables: a value of -1 means the two variables are perfectly negatively linearly correlated and a value of +1 means the two variables are perfectly positively linearly correlated. The figure below shows different values of the correlation coeffient and how they appear graphically.\n",
    "\n",
    "\n",
    "Although there can be non-linear relationships between the features and targets and correlation coefficients do not account for interactions between features, linear relationships are a good way to start exploring trends in the data. We can then use these values for selecting the features to employ in our model.\n",
    "\n",
    "The code below calculates the correlation coefficients between all the variables and the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all correlations and sort \n",
    "correlations_data = optimized_df.corr()['score'].sort_values()\n",
    "\n",
    "# Print the most negative correlations\n",
    "print(correlations_data.head(15), '\\n')\n",
    "\n",
    "# Print the most positive correlations\n",
    "print(correlations_data.tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the limited memory space in processing all the data, we'll select about 20 features to use for our analysis. We'll mainly select the those that have either a positive or negative correlation who may have a possibility of affecting the prediction of our score. I'll also include those that I believe would logically affect the chances of the malware attack such as your Firewall. Let's also include 2 additional categorical features (Platform & ProductName) in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ones you want\n",
    "optimized_df = optimized_df[['AVProductStatesIdentifier','Census_TotalPhysicalRAM','Wdft_IsGamer','Census_ProcessorCoreCount',\n",
    "                             'RtpStateBitfield','Census_OSBuildNumber','Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "                             'Census_InternalPrimaryDiagonalDisplaySizeInInches','Census_HasOpticalDiskDrive','Census_ProcessorModelIdentifier',\n",
    "                             'Census_InternalBatteryNumberOfCharges','AVProductsInstalled','Census_IsAlwaysOnAlwaysConnectedCapable',\n",
    "                             'Census_IsVirtualDevice','AVProductsEnabled',\n",
    "                             'Census_FirmwareManufacturerIdentifier',\n",
    "                             'Firewall','Platform','ProductName','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the numeric columns\n",
    "numeric_subset = optimized_df.select_dtypes('number')\n",
    "\n",
    "# Create columns with square root and log of numeric columns\n",
    "for col in numeric_subset.columns:\n",
    "    # Skip HasDetection Score column\n",
    "    if col == 'score':\n",
    "        next\n",
    "    else:\n",
    "        numeric_subset['sqrt_' + col] = np.sqrt(numeric_subset[col])\n",
    "        numeric_subset['log_' + col] = np.log(numeric_subset[col])\n",
    "\n",
    "# Select the categorical columns\n",
    "categorical_subset = optimized_df[['Platform','ProductName']]\n",
    "\n",
    "# One hot encode\n",
    "categorical_subset = pd.get_dummies(categorical_subset)\n",
    "\n",
    "# Join the two dataframes using concat\n",
    "# Make sure to use axis = 1 to perform a column bind\n",
    "features = pd.concat([numeric_subset, categorical_subset], axis = 1)\n",
    "\n",
    "# Drop columns without HasDetection value\n",
    "features = features.dropna(subset = ['score'])\n",
    "\n",
    "# Find correlations with the score \n",
    "correlations = features.corr()['score'].dropna().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Feature Engineering and Selection\n",
    "\n",
    "Now that we have explored the trends and relationships within the data, we can work on engineering a set of features for our models. We can use the results of the EDA to inform this feature engineering. In particular, we learned the following from EDA which can help us in engineering/selecting features:\n",
    "\n",
    "* The score distribution varies by ProductName and to a lesser extent by Platform. Although we will focus on numerical features, we should also include these two categorical features in the model.\n",
    "* Taking the log transformation of features does not result in significant increases in the linear correlations between features and the score\n",
    "\n",
    "Before we get any further, we should define what feature engineering and selection are! These definitions are informal and have considerable overlap, but I like to think of them as two separate processes:\n",
    "\n",
    "* [Feature Engineering](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/): The process of taking raw data and extracting or creating new features that allow a machine learning model to learn a mapping beween these features and the target. This might mean taking transformations of variables, such as we did with the log and square root, or one-hot encoding categorical variables so they can be used in a model. Generally, I think of feature engineering as adding additional features derived from the raw data.\n",
    "* [Feature Selection](https://machinelearningmastery.com/an-introduction-to-feature-selection/): The process of choosing the most relevant features in your) data. \"Most relevant\" can depend on many factors, but it might be something as simple as the highest correlation with the target, or the features with the [most variance](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html). In feature selection, we remove features that do not help our model learn the relationship between features and the target. This can help the model generalize better to new data and results in a more interpretable model. Generally, I think of feature selection as subtracting features so we are left with only those that are most important.\n",
    "\n",
    "Feature engineering and selection are iterative processes that will usually require several attempts to get right. Often we will use the results of modeling, such as the feature importances from a random forest, to go back and redo feature selection, or we might later discover relationships that necessitate creating new variables. Moreover, these processes usually incorporate a mixture of domain knowledge and statistical qualitites of the data.\n",
    "\n",
    "[Feature engineering and selection](https://www.featurelabs.com/blog/secret-to-data-science-success/) often has the highest returns on time invested in a machine learning problem. It can take quite a while to get right, but is often more important than the exact algorithm and hyperparameters used for the model. If we don't feed the model the correct data, then we are setting it up to fail and we should not expect it to learn!\n",
    "\n",
    "\n",
    "In this project, we will take the following steps for feature engineering:\n",
    "\n",
    "* Select only the numerical variables and two categorical variables\n",
    "* Add in the log transformation of the numerical variables\n",
    "* One-hot encode the categorical variables\n",
    "\n",
    "For feature selection, we will do the following:\n",
    "\n",
    "* Remove [collinear features](https://www.featurelabs.com/blog/secret-to-data-science-success/)\n",
    "\n",
    "We will discuss collinearity (also called [multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity) when we get to that process!\n",
    "\n",
    "The following code selects the numeric features, adds in log transformations of all the numeric features, selects and one-hot encodes the categorical features, and joins the sets of features together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Remove Collinear Features\n",
    "\n",
    "Highly [collinear features](http://psychologicalstatistics.blogspot.com/2013/11/multicollinearity-and-collinearity-in.html) have a significant correlation coefficent between them. Thus, to opmitimize our models, we should look to remove any of the collinear features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the original data\n",
    "features = optimized_df.copy()\n",
    "\n",
    "# Select the numeric columns\n",
    "numeric_subset = optimized_df.select_dtypes('number')\n",
    "\n",
    "# Create columns with log of numeric columns\n",
    "for col in numeric_subset.columns:\n",
    "    # Skip the target column\n",
    "    if col == 'score':\n",
    "        next\n",
    "    else:\n",
    "        numeric_subset['log_' + col] = np.log(numeric_subset[col])\n",
    "        \n",
    "# Select the categorical columns\n",
    "categorical_subset = optimized_df[['Platform','ProductName']]\n",
    "\n",
    "# One hot encode\n",
    "categorical_subset = pd.get_dummies(categorical_subset)\n",
    "\n",
    "# Join the two dataframes using concat\n",
    "# Make sure to use axis = 1 to perform a column bind\n",
    "features = pd.concat([numeric_subset, categorical_subset], axis = 1)\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_collinear_features(x, threshold):\n",
    "    '''\n",
    "    Objective:\n",
    "        Remove collinear features in a dataframe with a correlation coefficient\n",
    "        greater than the threshold. Removing collinear features can help a model\n",
    "        to generalize and improves the interpretability of the model.\n",
    "        \n",
    "    Inputs: \n",
    "        threshold: any features with correlations greater than this value are removed\n",
    "    \n",
    "    Output: \n",
    "        dataframe that contains only the non-highly-collinear features\n",
    "    '''\n",
    "    \n",
    "    # Dont want to remove correlations between Score\n",
    "    y = x['score']\n",
    "    x = x.drop(columns = ['score'])\n",
    "    \n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "    \n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "            \n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                # print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns = drops)\n",
    "\n",
    "    \n",
    "    # Add the score back in to the data\n",
    "    x['score'] = y\n",
    "               \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the collinear features above a specified correlation coefficient\n",
    "features = remove_collinear_features(features, 0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any columns with all na values\n",
    "features  = features.dropna(axis=1, how = 'all')\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training & Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the columns with no score and the columns with a score\n",
    "no_score = features[features['score'].isna()]\n",
    "score = features[features['score'].notnull()]\n",
    "\n",
    "print(no_score.shape)\n",
    "print(score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out the features and targets\n",
    "features = score.drop(columns='score')\n",
    "targets = pd.DataFrame(score['score'])\n",
    "\n",
    "# Replace the inf and -inf with nan (required for later imputation)\n",
    "features = features.replace({np.inf: np.nan, -np.inf: np.nan})\n",
    "\n",
    "# Split into 70% training and 30% testing set\n",
    "X, X_test, y, y_test = train_test_split(features, targets, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "print(y.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "So far, we've carried out the first three steps of a machine learning problem:\n",
    "\n",
    "    1) Cleaned and formatted the raw data\n",
    "    2) Performed an exploratory data analysis\n",
    "    3) Developed a set of features to train our model using feature engineering and feature selection\n",
    "\n",
    "We also completed the crucial task of establishing a baseline metric so we can determine if our model is better than guessing!\n",
    "We will now cover steps 4-6, which focus on implementing several machine learning methods, selecting the best model, and optimizing it for our problem using hyperparameter tuning with cross validation. As a final step here, we will save the datasets we developed to use again in the next part.\n",
    "\n",
    "## Imports\n",
    "We will use the standard data science and machine learning libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values and scaling values\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the no scores\n",
    "#no_score.to_csv('data/no_score.csv', index = False)\n",
    "\n",
    "#Give training, and testing data more recognizable names\n",
    "train_features = X\n",
    "test_features = X_test\n",
    "train_labels = y\n",
    "test_labels = y_test\n",
    "\n",
    "# Display sizes of data\n",
    "print('Training Feature Size: ', train_features.shape)\n",
    "print('Testing Feature Size:  ', test_features.shape)\n",
    "print('Training Labels Size:  ', train_labels.shape)\n",
    "print('Testing Labels Size:   ', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take an overview of the formatted feature columns we have so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling\n",
    "\n",
    "Once feature engineering/construction is done, we can get started with the machine learning! All of our data (both training and testing) is aggregated for each household and so can be directly used in a model. To first show the process of modeling, we'll use the capable Random Forest Classifier in Scikit-Learn. This probably won't get us to the top of the leaderboard, but it will allow us to establish a baseline. Later we'll try several other models including the powerful Gradient Boosting Machine.\n",
    "\n",
    "To assess our model, we'll use 10-fold cross validation on the training data. This will essentially _train and test the model 10 times_ using different splits of the training data. 10-fold cross validation is an effective method for estimating the performance of a model on the test set. We want to look at the average performance in cross validation as well as the standard deviation to see how much scores change between the folds. We use the `F1 Macro` measure to evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Custom scorer for cross validation\n",
    "scorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are going to be comparing different models, we want to scale the features (limit the range of each column to between 0 and 1). For many ensemble models this is not necessary, but when we use models that depend on a distance metric, such as KNearest Neighbors or the Support Vector Machine, feature scaling is an absolute necessity. When comparing different models, it's always safest to scale the features. We also impute the missing values with the median of the feature.\n",
    "\n",
    "For imputing missing values and scaling the features in one step, we can make a pipeline. This will be fit on the training data and used to transform the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_features.columns)\n",
    "\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Fit and transform training data\n",
    "train_features = pipeline.fit_transform(train_features)\n",
    "test_features = pipeline.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has no missing values and is scaled between zero and one. This means it can be directly used in any Scikit-Learn model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=10, \n",
    "                               n_jobs = -1)\n",
    "# 10 fold cross validation\n",
    "cv_score = cross_val_score(model, train_features, train_labels.values.ravel(), cv = 10, scoring = scorer)\n",
    "\n",
    "print(f'10 Fold Cross Validation Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_features, train_labels.values.ravel())\n",
    "\n",
    "# Feature importances into a dataframe\n",
    "feature_importances = pd.DataFrame({'feature': features, 'importance': model.feature_importances_})\n",
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a short function we'll use to plot the feature importances. I use this function a lot and often copy and paste it between scripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(df, n = 10, threshold = None):\n",
    "    \"\"\"Plots n most important features. Also plots the cumulative importance if\n",
    "    threshold is specified and prints the number of features needed to reach threshold cumulative importance.\n",
    "    Intended for use with any tree-based feature importances. \n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): Dataframe of feature importances. Columns must be \"feature\" and \"importance\".\n",
    "    \n",
    "        n (int): Number of most important features to plot. Default is 15.\n",
    "    \n",
    "        threshold (float): Threshold for cumulative importance plot. If not provided, no plot is made. Default is None.\n",
    "        \n",
    "    Returns:\n",
    "        df (dataframe): Dataframe ordered by feature importances with a normalized column (sums to 1) \n",
    "                        and a cumulative importance column\n",
    "    \n",
    "    Note:\n",
    "    \n",
    "        * Normalization in this case means sums to 1. \n",
    "        * Cumulative importance is calculated by summing features from most to least important\n",
    "        * A threshold of 0.9 will show the most important features needed to reach 90% of cumulative importance\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    \n",
    "    # Sort features with most important at the head\n",
    "    df = df.sort_values('importance', ascending = False).reset_index(drop = True)\n",
    "    \n",
    "    # Normalize the feature importances to add up to one and calculate cumulative importance\n",
    "    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "    df['cumulative_importance'] = np.cumsum(df['importance_normalized'])\n",
    "    \n",
    "    plt.rcParams['font.size'] = 12\n",
    "    \n",
    "    # Bar plot of n most important features\n",
    "    df.loc[:n, :].plot.barh(y = 'importance_normalized', \n",
    "                            x = 'feature', color = 'darkgreen', \n",
    "                            edgecolor = 'k', figsize = (12, 8),\n",
    "                            legend = False, linewidth = 2)\n",
    "\n",
    "    plt.xlabel('Normalized Importance', size = 18); plt.ylabel(''); \n",
    "    plt.title(f'{n} Most Important Features', size = 18)\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    \n",
    "    if threshold:\n",
    "        # Cumulative importance plot\n",
    "        plt.figure(figsize = (8, 6))\n",
    "        plt.plot(list(range(len(df))), df['cumulative_importance'], 'b-')\n",
    "        plt.xlabel('Number of Features', size = 16); plt.ylabel('Cumulative Importance', size = 16); \n",
    "        plt.title('Cumulative Feature Importance', size = 18);\n",
    "        \n",
    "        # Number of features needed for threshold cumulative importance\n",
    "        # This is the index (will need to add 1 for the actual number)\n",
    "        importance_index = np.min(np.where(df['cumulative_importance'] > threshold))\n",
    "        \n",
    "        # Add vertical line to plot\n",
    "        plt.vlines(importance_index + 1, ymin = 0, ymax = 1.05, linestyles = '--', colors = 'red')\n",
    "        plt.show();\n",
    "        \n",
    "        print('{} features required for {:.0f}% of cumulative importance.'.format(importance_index + 1, \n",
    "                                                                                  100 * threshold))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fi = plot_feature_importances(feature_importances, threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, the processor model identifier seems to be the most important feature followed by the InternalDiagonalDisplaySizeinInches.\n",
    "It's interesting that we only need 12 of the ~58 features to account for 90% of the importance. This tells us that we may be able to remove some of the features. However, feature importances don't tell us which direction of the feature is important (for example, we can't use these to tell whether newer or older processor model identifiers lead to malware infection) they only tell us which features the model considered relevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "Now that we have a good set of features, it's time to get into the modeling. We already tried one basic model, the Random Forest Classifier which delivered a best macro F1 of 0.35. However, in machine learning, there is no way to know ahead of time which model will work best for a given dataset. The following plot shows that __there are some problems where even Gaussian Naive Bayes will outperform a gradient boosting machine__. This is from [an excellent paper by Randal Olson that discusses many points of machine learning](https://psb.stanford.edu/psb-online/proceedings/psb18/olson.pdf)\n",
    "\n",
    "![algorithm_comparison](https://raw.githubusercontent.com/WillKoehrsen/Machine-Learning-Projects/master/algorithm_comparison.png)\n",
    "\n",
    "What this plot tells us is that we have to try out a number of different models to see which is optimal. Most people eventually settle on the __gradient boosting machine__ and we will try that out, but for now we'll take a look at some of the other options.  There are literally dozens (maybe hundreds) of multi-class machine learning models if we look at the [Scikit-Learn documentation](http://scikit-learn.org/stable/modules/multiclass.html). We don't have to try them all, but we should sample from the options.\n",
    "\n",
    "What we want to do is write a function that can evaluate a model. This will be pretty simple since we already wrote most of the code. In addition to the Random Forest Classifier, we'll try eight other Scikit-Learn models. Luckily, this dataset is relatively small and we can rapidly iterate through the models. We will make a dataframe to hold the results and the function will add a row to the dataframe for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model imports\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeClassifierCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Filter out warnings from models\n",
    "warnings.filterwarnings('ignore', category = ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore', category = DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category = UserWarning)\n",
    "\n",
    "# Dataframe to hold results\n",
    "model_results = pd.DataFrame(columns = ['model', 'cv_mean', 'cv_std'])\n",
    "\n",
    "def cv_model(train, train_labels, model, name, model_results=None):\n",
    "    \"\"\"Perform 10 fold cross validation of a model\"\"\"\n",
    "    \n",
    "    cv_scores = cross_val_score(model, train, train_labels.values.ravel(), cv = 10, scoring=scorer, n_jobs = -1)\n",
    "    print(f'10 Fold CV Score: {round(cv_scores.mean(), 5)} with std: {round(cv_scores.std(), 5)}')\n",
    "    \n",
    "    if model_results is not None:\n",
    "        model_results = model_results.append(pd.DataFrame({'model': name, \n",
    "                                                           'cv_mean': cv_scores.mean(), \n",
    "                                                            'cv_std': cv_scores.std()},\n",
    "                                                           index = [0]),\n",
    "                                             ignore_index = True)\n",
    "\n",
    "        return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = cv_model(train_features, train_labels, LinearSVC(), \n",
    "                         'LSVC', model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = cv_model(train_features, train_labels, \n",
    "                         GaussianNB(), 'GNB', model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_results = cv_model(train_features, train_labels, \n",
    "                         MLPClassifier(hidden_layer_sizes=(32, 64, 128, 64, 32)),\n",
    "                         'MLP', model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = cv_model(train_features, train_labels, \n",
    "                          LinearDiscriminantAnalysis(), \n",
    "                          'LDA', model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = cv_model(train_features, train_labels, \n",
    "                         RidgeClassifierCV(), 'RIDGE', model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [5, 10, 20]:\n",
    "    print(f'\\nKNN with {n} neighbors\\n')\n",
    "    model_results = cv_model(train_features, train_labels, \n",
    "                             KNeighborsClassifier(n_neighbors = n),\n",
    "                             f'knn-{n}', model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model_results = cv_model(train_features, train_labels, \n",
    "                         ExtraTreesClassifier(n_estimators = 100, random_state = 10),\n",
    "                         'EXT', model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Model Performance\n",
    "\n",
    "With the modeling results in a dataframe, we can plot them to see which model does the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = cv_model(train_features, train_labels,\n",
    "                          RandomForestClassifier(100, random_state=10),\n",
    "                              'RF', model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.set_index('model', inplace = True)\n",
    "model_results['cv_mean'].plot.bar(color = 'orange', figsize = (8, 6),\n",
    "                                  yerr = list(model_results['cv_std']),\n",
    "                                  edgecolor = 'k', linewidth = 2)\n",
    "plt.title('Model F1 Score Results');\n",
    "plt.ylabel('Mean F1 Score (with error bar)');\n",
    "model_results.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most likely candidate seems to be the Random Forest because it does best right out of the box.  While we didn't tune any of the hyperparameters so the comparison between models is not perfect, these results reflect those of many other Kaggle competitiors finding that tree-based ensemble methods (including the Gradient Boosting Machine) perform very well on structured datasets. Hyperparameter performance does improve the performance of machine learning models, but we don't have time to try all possible combinations of settings for all models. The graph below ([from the paper by Randal Olson](https://psb.stanford.edu/psb-online/proceedings/psb18/olson.pdf)) shows the effect of hyperparameter tuning versus the default values in Scikit-Learn.\n",
    "\n",
    "![hyperparameter_improvement](https://raw.githubusercontent.com/WillKoehrsen/Machine-Learning-Projects/master/hyperparameter_improvement.png)\n",
    "\n",
    "In most cases the accuracy gain is less than 10% so the worst model is probably not suddenly going to become the best model through tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
